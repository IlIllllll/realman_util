import cv2
import opuslib
import pyrealsense2 as rs
import sounddevice as sd
import numpy as np
import socket
import threading
import json
import time
import sys
import os
import argparse
from scipy.spatial.transform import Rotation as R

# ========== æ·»åŠ  realman æ¨¡å—è·¯å¾„ ==========
# å‡è®¾ realman æ–‡ä»¶å¤¹ä¸æœ¬è„šæœ¬åŒçº§ï¼Œå¦‚æœ‰ä¸åŒè¯·è‡ªè¡Œè°ƒæ•´
# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from robot_arm_interface import  RobotArmFactory, ArmConfig
from robot_arm_interface.plugins.realman_arm import RealmanRobotArm, rpy_to_rotation_vector, rotation_vector_to_rpy

# from realman.realman_utils import Realman, apply_rotation_delta
# from realman.contoller_move import ControlMove

# ========== é…ç½® ==========
# åˆ›å»ºæ‘„åƒå¤´å¯¹åº”çš„pipelineå’Œé…ç½®
pipelines = {}
AUDIO_PORT = 5007
VIDEO_PORT = 5006
CONTROL_PORT = 5005  # æ§åˆ¶ç«¯å£ï¼Œç›‘å¬ Unity æ§åˆ¶å‘½ä»¤

positionScale = 1
rotationScale = 1

def map_unity_quat_to_robot(unity_quat):
    # è¾“å…¥ Unity å››å…ƒæ•°ï¼š[x, y, z, w]
    r_unity = R.from_quat(unity_quat)
    
    # æ„é€ åæ ‡ç³»æ—‹è½¬çŸ©é˜µ M
    M = np.array([
        [-1, 0, 0], 
        [0, -1, 0],
        [0, 0, 1]
    ])
    
    # æ—‹è½¬çŸ©é˜µè¡¨ç¤ºå§¿æ€å˜æ¢
    R_unity_matrix = r_unity.as_matrix()
    R_robot_matrix = M @ R_unity_matrix @ M.T

    r_robot = R.from_matrix(R_robot_matrix)
    quat_xyzw = r_robot.as_quat()
    return quat_xyzw

def apply_rotation_delta(handType, init_euler_deg, delta_quat_unity, rotation_scale=1.0):
    # å°† Unity å››å…ƒæ•°è½¬æ¢åˆ°æœºå™¨äººåæ ‡ç³»
    delta_quat_robot = map_unity_quat_to_robot(delta_quat_unity)

    # æŠŠå››å…ƒæ•°è½¬ä¸º angle-axis
    delta_rot = R.from_quat(delta_quat_robot)
    angle_axis = delta_rot.as_rotvec()  # è¿™æ˜¯ angle * axis çš„å½¢å¼

    if handType == "left":
        angle_axis[2] *= -1  # æ‰‹åŠ¨åè½¬ç»• Z çš„æ—‹è½¬
    if handType == "right":
        # âœ… åè½¬ X è½´æ—‹è½¬æ–¹å‘
        angle_axis[0] *= -1  # æ‰‹åŠ¨åè½¬ç»• X çš„æ—‹è½¬
        
    # ç¼©æ”¾è§’åº¦
    scaled_rotvec = angle_axis * rotation_scale
    scaled_delta_rot = R.from_rotvec(scaled_rotvec)

    # åˆå§‹å§¿æ€
    init_rot = R.from_euler('ZYX', init_euler_deg, degrees=False)

    # åº”ç”¨æ—‹è½¬å¢é‡
    final_rot = scaled_delta_rot * init_rot
    return final_rot.as_euler('ZYX', degrees=False)

# ========== éŸ³é¢‘ ==========
class AudioStreamer:
    def __init__(self, ip="0.0.0.0", port=AUDIO_PORT):
        self.ip = ip
        self.port = port
        self.sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        self.sock.bind((ip, port))
        self.running = False
        self.target_addr = None

        # Opus ç¼–ç å™¨åˆå§‹åŒ–ï¼ˆé‡‡æ ·ç‡: 16000, é€šé“æ•°: 1, åº”ç”¨: VOIPï¼‰
        self.encoder = opuslib.Encoder(16000, 1, opuslib.APPLICATION_AUDIO)

    def audio_callback(self, indata, frames, time_info, status):
        if not self.running or self.target_addr is None:
            return
        pcm = (indata * 32767).astype(np.int16).tobytes()
        try:
            encoded = self.encoder.encode(pcm, frame_size=320)  # 20ms = 16000Hz * 0.02s = 320 samples
            self.sock.sendto(encoded, self.target_addr)
        except Exception as e:
            print("[Audio Encode Error]", e)

    def run(self):
        print(f"[Audio] Listening on {self.ip}:{self.port}")
        while True:
            data, addr = self.sock.recvfrom(1024)
            msg = data.decode()
            if msg == "start":
                self.target_addr = addr
                self.running = True
                print("[Audio] Received start. Begin streaming.")
                stream = sd.InputStream(channels=1, samplerate=16000, dtype='float32', callback=self.audio_callback, blocksize=320)
                with stream:
                    while self.running:
                        time.sleep(0.1)
            elif msg == "stop":
                print("[Audio] Received stop.")
                self.running = False

# ========== è§†é¢‘æµçº¿ç¨‹ ==========
def video_stream_thread(ip="0.0.0.0", port=VIDEO_PORT, device_serials=None):
    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    sock.bind((ip, port))
    print(f"[Video] Listening on {ip}:{port}")
    print(f"ğŸ” ç­‰å¾…æ¥è‡ª Unity çš„æ¶ˆæ¯ï¼ˆå‘½ä»¤æˆ–å›¾åƒè¯·æ±‚ï¼‰...")
    client_addr = None
    while True:
        data, addr = sock.recvfrom(65535)
        # å¦‚æœæ”¶åˆ°çš„æ˜¯â€œstartâ€å‘½ä»¤ï¼Œè®°å½•å®¢æˆ·ç«¯åœ°å€
        if data.decode(errors='ignore') == "start":
            client_addr = addr
            print(f"âœ… æ”¶åˆ° start å‘½ä»¤ï¼Œæ¥è‡ª {addr}")
            break  # è·³å‡ºç­‰å¾…ï¼Œå¼€å§‹æ¨æµ

    for name, serial in device_serials.items():
        pipeline = rs.pipeline()
        config = rs.config()
        config.enable_device(serial)
        config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)
        pipeline.start(config)
        pipelines[name] = pipeline
    print(f"[Video] å¼€å§‹æ¨æµ")
    while True:
        # é‡‡é›†æ¯ä¸ªå‘½åæ‘„åƒå¤´çš„å›¾åƒ
        frames = {}
        for name, pipeline in pipelines.items():
            frame = pipeline.wait_for_frames().get_color_frame()
            if not frame:
                break
            frames[name] = np.asanyarray(frame.get_data())

        if len(frames) != 3:
            continue  # å¦‚æœæ²¡è·å–åˆ°å…¨éƒ¨ä¸‰ä¸ªå›¾åƒå°±è·³è¿‡

        # ä¿è¯å›ºå®šé¡ºåºæ‹¼æ¥ï¼ˆæ¯”å¦‚ï¼šå·¦ã€ä¸Šã€å³ï¼‰
        img_left = cv2.rotate(frames['left'], cv2.ROTATE_90_CLOCKWISE)
        img_top = frames['top']
        img_right = cv2.rotate(frames['right'], cv2.ROTATE_90_CLOCKWISE)

        # å‡è®¾ img_left, img_top, img_right æ˜¯å·²ç»è·å–åˆ°çš„ 3 å¹…å›¾åƒ
        # 1. ç»Ÿä¸€å°ºå¯¸ï¼ˆå¯é€‰ï¼‰ï¼šresize æ‰€æœ‰å›¾åƒåˆ°ä¸€è‡´å¤§å°
        # 2. è®¡ç®—ç¼©æ”¾å°ºå¯¸
        top_h, top_w = img_top.shape[:2]
        thumb_w, thumb_h = top_w * 2 // 5, top_h * 2 // 5 # ç¼©å°ä¸º top å›¾åƒçš„ 1/4

        # 3. ç¼©å°å·¦ã€å³å›¾åƒ
        img_left_small = cv2.resize(img_left, (thumb_w, thumb_h))
        img_right_small = cv2.resize(img_right, (thumb_w, thumb_h))

        # 4. æ‹·è´ top å›¾åƒä»¥ä¾¿ç»˜åˆ¶
        combined_img = img_top.copy()

        # 5. å°†ç¼©å°åçš„å·¦å›¾åƒç²˜è´´åˆ°å·¦ä¸Šè§’
        combined_img[0:thumb_h, 0:thumb_w] = img_left_small

        # 6. å°†ç¼©å°åçš„å³å›¾åƒç²˜è´´åˆ°å³ä¸Šè§’
        combined_img[0:thumb_h, top_w - thumb_w:top_w] = img_right_small

        # 7. combined_img å°±æ˜¯åˆå¹¶åç»“æœ

        # JPEG ç¼–ç 
        _, jpeg = cv2.imencode('.jpg', combined_img, [cv2.IMWRITE_JPEG_QUALITY, 80])
        
        # UDP å‘é€
        sock.sendto(jpeg.tobytes(), client_addr)

# ========== æ§åˆ¶çº¿ç¨‹ ==========
def command_server_thread(ip="0.0.0.0", port=CONTROL_PORT):
    # control = ControlMove()
    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    sock.bind((ip, port))
    print(f"[Control] Listening on {ip}:{port}")

    arm_config = ArmConfig(
        name="double_arm",
        dof=14,
        ip=["192.168.1.18", "192.168.1.19"],
        max_joint_velocities=np.array([2.0] * 14),
        max_joint_accelerations=np.array([5.0] * 14),
        joint_limits_lower=np.array([-np.pi] * 14),
        joint_limits_upper=np.array([np.pi] * 14),
        control_frequency=100.0
    )

    robot_arm = RobotArmFactory.create("realman", arm_config)
    robot_arm.connect()
    time.sleep(1)
    robot_arm.enable()
    print(f"[Control] Connected to robot arm")
    while True:
        data, addr = sock.recvfrom(65535)
        try:
            msg = data.decode("utf-8")
            if msg == "connect":
                # for name in arms:
                #     init_pose[name] = arms[name].read("Present_Pose").tolist()
                sock.sendto("connect success".encode("utf-8"), addr)
                init_pose = {
                    "left": robot_arm.get_state().end_effector_pose[:7],
                    "right": robot_arm.get_state().end_effector_pose[7:]
                }
                last_pose = {
                    "left": init_pose["left"],
                    "right": init_pose["right"]
                }
                print(f"[Control] Initial Pose: {init_pose}")
                # print(f"[{addr}] CONNECT â†’ {init_pose}")
            elif msg == "disconnect":
                sock.sendto("disconnect success".encode("utf-8"), addr)
                print(f"[{addr}] DISCONNECT")
            elif msg in ["start_stick_axis", "stop_stick_axis"]:
                print(f"[{addr}] {msg}")
            else:
                data = json.loads(msg)
                if data.get("x"):
                    # handType = data["handType"]
                    # if handType == "left":
                    #     control.start(0, data["y"])
                    # else:
                    #     control.start(data["x"], 0)
                    print(f"x[{addr}] {data}")
                elif data.get("deltaPose"):
                    print(f"deltaPose[{addr}] {data}")
                    handType = data["handType"]
                    deltaPose = data["deltaPose"]
                    grip = data.get("grip", 0.0)

                    # åæ ‡å˜æ¢
                    if handType == "left":
                        xyzDelta = np.array([-deltaPose[1], -deltaPose[2], -deltaPose[0]]) * positionScale
                    else:
                        xyzDelta = np.array([deltaPose[1], -deltaPose[2], deltaPose[0]]) * positionScale
                    
                    rpy = apply_rotation_delta(handType, init_pose[handType][3:6], deltaPose[3:7], rotationScale)
                    xyz = init_pose[handType][:3] + xyzDelta * positionScale
                    pose = np.concatenate([xyz, rpy, [grip]])
                    
                    send_pose = np.zeros(14)
                    if handType == "left":
                        send_pose[:7] = pose
                        send_pose[7:] = last_pose["right"]
                    else:
                        send_pose[:7] = last_pose["left"]
                        send_pose[7:] = pose
                    # å‘é€çš„åº”è¯¥æ˜¯ä¸Šä¸€ä¸ªpose
                    robot_arm.move_cartesian(send_pose)
                    last_pose[handType] = pose
        except Exception as e:
            print(f"[{addr}] Failed to parse message: {e}")

# ========== å¯åŠ¨å…¥å£ ==========
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="å¯åŠ¨è§†é¢‘æµæˆ–æŒ‡ä»¤æœåŠ¡çº¿ç¨‹")
    parser.add_argument("--mode", nargs='+', choices=["video", "command", "audio"], default=["video", "command"],
                    help="è¿è¡Œæ¨¡å¼: å¯é€‰ 'video' 'command' 'audio'ï¼Œæ”¯æŒå¤šä¸ªï¼Œä¾‹å¦‚ --mode video command")
    
    parser.add_argument("--ip", type=str, default="17.16.2.88",
                    help="ç”¨äºé€‰æ‹©æ‘„åƒå¤´åºåˆ—å·é…ç½®ï¼Œä¾‹å¦‚ '17.16.2.88' æˆ– '17.16.2.206'")
    args = parser.parse_args()
    print(f"è¿è¡Œæ¨¡å¼: {args.mode}, ä½¿ç”¨æ‘„åƒå¤´é…ç½®IP: {args.ip}")

    if args.ip == "17.16.2.88":
        DEVICE_SERIALS = {
            'left': '130322272067',
            'right': '130322271353',
            'top': '130322273389'
        }
    elif args.ip == "17.16.2.206":
        DEVICE_SERIALS = {
            'left': '130322270966',
            'right': '130322271356',
            'top': '130322273093'
        }
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„ IP é…ç½®å°¾å·: {args.ip}ï¼Œè¯·ä½¿ç”¨ '88' æˆ– '206'")
    
    if "video" in args.mode:
        t1 = threading.Thread(target=video_stream_thread, kwargs={"device_serials": DEVICE_SERIALS})
        t1.start()

    if "command" in args.mode:
        t2 = threading.Thread(target=command_server_thread)
        t2.start()

    if "audio" in args.mode:
        audio_streamer = AudioStreamer()
        t3 = threading.Thread(target=audio_streamer.run)
        t3.start()

    # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹ç»“æŸ
    if "video" in args.mode:
        t1.join()
    if "command" in args.mode:
        t2.join()
    if "audio" in args.mode:
        t3.join()